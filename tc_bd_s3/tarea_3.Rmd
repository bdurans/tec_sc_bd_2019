---
title: "Tarea 3"
author: "Curso Big Data TEC"
date: "20191214"
output: html_document
editor_options: 
  chunk_output_type: console
---

## Tarea sesión 3

Descripción :
Debe generar un pdf, en el cual se expliqué los pasos que utilizó para conectarse a Spark desde R utilizando sparklyr. Mostar por medio de imágenes y su respectiva explicación de cada uno de los siguientes puntos:

Versión de Java
Instalación de librerías y Spark
Conexión a Spark
Conexión a la web IU de Spark
Desconexión a Spark
Además debe crear RMarkdown donde al menos utilice 3 datasets en los cuales aplique 3 funciones vistas en clases ("Filter,mutate ......") y con su respectivo gráfico para demostrar el resultado final utilizando SPARK y salvar los datos obtenidos.

#Nota: Si eres una de las personas que no utiliza los datos del gobierno, por favor contacta al profesor para decidir sobre cuales datos vas a trabajar.


## Copia datos

Copia los datos 

```{r}
library(nycflights13)
vuelos <- # aqui el codigo para copiar nycflights13::flights a Spark
aerolineas <- # aqui el codigo para copiar nycflights13::airlines a Spark
```

Pregunta: 

> Cuandos RDD creó el paso arriba?

### Ejecuta un join sobre spark

```{r}
# join (sobre spark) de vuelos y aerolineas
```

### Ejecuta un group_by sobre spark

```{r}
# group_by por aerolinea reportando promedio de lo retrasos
```

pregunta:

> Que pasa cuando cierras la sesión y la vuelves a abrir? 
> estan los resultados que tenias antes aun en tu instancia de Spark? 
> Explica lo que observas.

```{r}
# Standalone connection
# conf <- spark_config()
# conf$spark.executor.memory <- "2GB"
# conf$spark.memory.fraction <- 0.9
# conf$spark.executor.cores <- 2
# conf$spark.dynamicAllocation.enabled <- "false"

# sc <- spark_connect(master="spark://master-url:7077", 
#              version = "2.1.0",
#              config = conf,
#              spark_home = "/opt/spark/")
```

```{r}
library(sparklyr)
sc <- spark_connect(master = "local")
```

